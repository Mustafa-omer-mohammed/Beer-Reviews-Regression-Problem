{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informative-fellow",
   "metadata": {},
   "source": [
    "# Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # algebraic computations , read and write to csv \n",
    "\n",
    "import numpy as np # linear algebra and arrays muniplication \n",
    "\n",
    "\n",
    "############  importing the data visualization libraries :##############\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm # Creating a normaly distributed curve\n",
    "\n",
    "##################### Importing the Regression Models ####################\n",
    "from sklearn. ensemble import RandomForestRegressor # Random forest regressor model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Importing a model to split the training set from the evaluation set\n",
    "from sklearn. model_selection import train_test_split \n",
    "\n",
    "############# R2 as the unit of evaluation measure #################\n",
    "from sklearn. metrics import r2_score                \n",
    "\n",
    "############  RandomizedSearchCV #################\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "################## Tuxtual data prprocessing ##################\n",
    "from sklearn. feature_extraction.text import TfidfVectorizer \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "import re\n",
    "import string\n",
    "\n",
    "############################## Import Utility Functions ################################\n",
    "\n",
    "from packages.utils import *  # import utils from packages customized module contain all neccessary function for the project \n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-notebook' ) # plotting style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('./development.tsv',sep=\"\\t\")\n",
    "df_eval = pd.read_csv('./evaluation.tsv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-jason",
   "metadata": {},
   "source": [
    "## Data Exploration and Feature engineering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the features  \n",
    "print(f\"the lenght of the development_set = {len(df_dev)} \" )\n",
    "print(f\"the lenght of the evaluation_set = {len(df_eval)} \" )\n",
    "df_dev.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_dev.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now we can merge the development and the evaluation data sets  for better data cleaning and preprocessing synchronously \n",
    "df = pd.concat([df_dev, df_eval], sort=False )\n",
    "len(df_dev), len(df_eval), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to better deal with the columns we will rename them with single word each \n",
    "rename = {\"beer/ABV\" : \"abv\", \"beer/name\" : \"beerName\" ,\"beer/style\" : \"beerstyle\" , \"review/appearance\" :\"apperance\" , \"review/aroma\" : \"aroma\" ,'review/overall' : 'overall' , 'review/palate':'palate' , \\\n",
    "          'review/taste' :\"taste\" , 'review/text' : 'text' , 'user/gender' : \"gender\" , 'user/profileName' : \"profilename\" ,'user/ageInSeconds' : 'age' }\n",
    "df.rename(columns = rename , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the % of NANs value in the features \n",
    "print(df.drop([\"overall\"],axis=1).isnull().sum(axis=0)*100/len(df),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy version to be used in version 2 of the code\n",
    "df_v2 = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-coffee",
   "metadata": {},
   "source": [
    "## Target Variable Exploration :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyize the distribution of quality we will use seaborn to visualize the distribution\n",
    "\n",
    "reviews = df[\"overall\"].dropna() # in order to plot we need to drop the NAN values comes from the evaluation set\n",
    "sns.distplot(x=df[\"overall\"],norm_hist=False )\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We found that the target variable is skewed left and the median is 4 \n",
    "sns.boxplot(x=reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(reviews, ddof= 1)\n",
    "mean = np.mean(reviews)\n",
    "median = np.median(reviews)\n",
    "\n",
    "print(f\"Reviews is not normaly distributed with mean = {mean:.2f} and standard deviation = {std:.2f} and median = {median:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-humor",
   "metadata": {},
   "source": [
    "## V1- simple Imputation without text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-mandate",
   "metadata": {},
   "source": [
    "### \"profileName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the feature profilename has cradinality of {df.profilename.nunique()} \\n \")\n",
    "data_visualization_histogram(\"profilename\" , df , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"user/profileName\" have \n",
    "x = df[\"profilename\"].copy()\n",
    "x[x.replace(x.value_counts().to_dict()) < 50] = 'other values'\n",
    "x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"profilename\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the NaN  values with the most frequent value \n",
    "\n",
    "df[\"profilename\"].fillna(df[\"profilename\"].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"profilename\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before handling beername and style we must check if they are redundant features \n",
    "mask = df[\"beerstyle\"] == df[\"beerName\"]\n",
    "print(f\"there is {df.loc[mask ,['beerstyle','beerName'] ].nunique()} redundant unique values between the 2 features\")\n",
    "len(df.loc[mask ,[\"beerstyle\" , \"beerName\"] ])/len(df[\"beerstyle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-drunk",
   "metadata": {},
   "source": [
    "### 'beer/name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the feature profilename has cradinality of {df.beerName.nunique()} \")\n",
    "data_visualization_histogram(\"beerName\" , df , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"beerName\" after discritizing it \n",
    "x = df.beerName.copy()\n",
    "x[x.replace(x.value_counts().to_dict()) < 130] = 'others'\n",
    "x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"beerName\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no nulls in this attribute\n",
    "df[\"beerName\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-deployment",
   "metadata": {},
   "source": [
    "### beer/Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.beerstyle.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the feature profilename has cradinality of {df.beerstyle.nunique()} \")\n",
    "data_visualization_histogram(\"beerstyle\" , df , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"beerName\" after discritizing it \n",
    "x = df[\"beerstyle\"].copy()\n",
    "x[x.replace(x.value_counts().to_dict()) < 100] = 'others'\n",
    "x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"beerstyle\"] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-collar",
   "metadata": {},
   "source": [
    "### 'beer/ABV'  alcahole per volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'beer/ABV'  alcahole per volume  we check the NANs \n",
    "df['abv'].isnull().sum()\n",
    "p =  df['abv'].isnull().sum()/len(df['abv'])\n",
    "print(f\"the percentage of nulls = {p}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we replace the NANs with the mean value of ABV\n",
    "mean_ABV = df['abv'].mean()\n",
    "df['abv'].fillna(value = mean_ABV , inplace = True)\n",
    "p =  df['abv'].isnull().sum()/len(df['abv'])\n",
    "print(f\"the percentage of nulls = {p}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-assignment",
   "metadata": {},
   "source": [
    "### user/gender  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we found it higly unbalanced and contain over 60% missing values \n",
    "nulls = df[\"gender\"].isnull().sum() / len(df[\"gender\"])\n",
    "print(f\" gender containg {nulls*100:.2f} % null values \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev[\"user/gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rename.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-license",
   "metadata": {},
   "source": [
    "#### Categorical Feature Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will exclude \"Text review\" attribute for now hence it needs other type of transformation \n",
    "cat_col = ['beerName' , 'beerstyle' , 'profilename' ]\n",
    "df_one_h = pd.get_dummies(df,columns= cat_col , drop_first=True) #we set drop_first to true to remove the orininagl encoded columns\n",
    "df_one_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-usage",
   "metadata": {},
   "source": [
    "### V1-Training without Text Analysis & gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropped_Columns = [ 'text', \"age\", 'user/birthdayRaw','user/birthdayUnix', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid ,X_train_valid ,y_train_valid,X_test,y_test,feature_names ,index  = train_val_test(Dropped_Columns ,df_one_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-consent",
   "metadata": {},
   "source": [
    "### training models baselines  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Default :\n",
    "lasso_default = Lasso(tol=0.1 , alpha = 0.1)\n",
    "make_regression(lasso_default ,X_train , y_train  ,X_valid, y_valid )\n",
    "\n",
    "# Ridge Regularization model:\n",
    "ridge_default =  Ridge()\n",
    "make_regression(ridge_default ,X_train , y_train ,X_valid, y_valid  )\n",
    "\n",
    "# RANDOM FOREST REGRESSOR \n",
    "RF_default = RandomForestRegressor(random_state=42 , n_jobs=-1)\n",
    "make_regression(RF_default ,X_train , y_train , X_valid, y_valid )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-america",
   "metadata": {},
   "source": [
    "#### Predection of Basline Models on Test Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(RF_default,X_train_valid, y_train_valid,X_test ,\"RandomForest_Default\" ,index)\n",
    "print_results(lasso_default ,X_train_valid, y_train_valid,X_test,\"lasso_default\" , index)\n",
    "print_results(ridge_default,X_train_valid, y_train_valid,X_test, \"Ridge_default\" , index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-chorus",
   "metadata": {},
   "source": [
    "### Randomize Grid Search : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-fetish",
   "metadata": {},
   "source": [
    "##### Ridge HyperParameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplha the regularization parameter\n",
    "alpha = [float(x) for x in np.linspace(start = 0.01, stop = 3, num = 10)] # 10\n",
    "alpha.append(2.0)\n",
    "# Fit_Intercept \n",
    "fit_intercept = [True, False] # 2\n",
    "#Tolerance :\n",
    "tol = [0.001,0.01 , 0.005]\n",
    "# solver \n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'] # 7\n",
    "\n",
    "Ridge_random_grid = {'fit_intercept': fit_intercept,\n",
    "               'alpha': alpha,\n",
    "               'solver': solver,\n",
    "                'tol'  : tol,\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-piano",
   "metadata": {},
   "source": [
    "##### Random Forest Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1200, num = 21)]\n",
    "# criterion The function to measure the quality of a split\n",
    "criterion = ['mse', 'MAE']\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [20, 15, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "RF_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'criterion': criterion,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'bootstrap': bootstrap }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-spotlight",
   "metadata": {},
   "source": [
    "##### lasso Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the regularization Term\n",
    "alphas = np.array([ 0.01, 0.001, 0.0001,0.00001,0.000001 , 0.0000001])\n",
    "# selection \n",
    "selection = ['random' , 'cyclic']\n",
    "\n",
    "lasso_grid = { 'alpha' : alphas,\n",
    "               'selection':selection ,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-exposure",
   "metadata": {},
   "source": [
    "### Randomize Grid Search Results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_d = Lasso()\n",
    "Lasso_best = RandomizeGridSearch(lasso_d ,lasso_grid ,X_train_valid , y_train_valid, n_iter=100 ,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "Ridge_best = RandomizeGridSearch ( ridge , Ridge_random_grid ,X_train_valid , y_train_valid,100 ,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor(random_state=42 )\n",
    "RF_best = RandomizeGridSearch ( RF , RF_grid ,X_train_valid , y_train_valid , 150 ,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-permission",
   "metadata": {},
   "source": [
    "#### Predection of Best Models on Test Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(Lasso_best,X_train_valid, y_train_valid,X_test ,\"Lasso_best_V1\" ,index)\n",
    "print_results(Ridge_best ,X_train_valid, y_train_valid,X_test,\"Ridge_best_V1\" , index)\n",
    "print_results(RF_best,X_train_valid, y_train_valid,X_test, \"RF_best_V1\" , index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-addition",
   "metadata": {},
   "source": [
    "# V2-Text Analysis + Advanced Imputation + Gender Feature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-artwork",
   "metadata": {},
   "source": [
    "### A-Handling Missing Values with Advanced Imputation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-present",
   "metadata": {},
   "source": [
    "#### 1- user/gender + ABV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df_v2[\"gender\"].isnull().sum() / len(df_v2[\"gender\"])\n",
    "print(f\" gender containg {nulls*100:.2f} % null values \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df_v2[\"abv\"].isnull().sum() / len(df_v2[\"abv\"])\n",
    "print(f\" abv containg {nulls*100:.2f} % null values \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gender feature is higly impalanced so we need a better imputation methood than the simple imputer with frequancy \n",
    "df_v2[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-affect",
   "metadata": {},
   "source": [
    "#### KNN imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we will consider only the numerical features including the target variable \n",
    "## we don't consider the target variable because we want to apply the same transformation to both eval and dev set and eval has no column for the target variable \n",
    "features = ['abv', 'apperance', 'aroma','palate', 'taste' , 'gender' , 'overall','age']\n",
    "df_c = df_v2[features].copy(deep=True)\n",
    "# we match the index \n",
    "df_c.set_index(df_v2.index , inplace = True)\n",
    "print(df_c.columns)\n",
    "print(np.sum(df_c.index == df_v2.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_c_train is to be used to fit the scaler\n",
    "train_mask = ~df_c[\"overall\"].isna()\n",
    "df_c_train = df_c.copy(deep=True).loc[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapage (age) :\n",
    "    age_days = float(age) // (24 * 3600)\n",
    "    return age_days \n",
    "df_c['agedays']=df_c['age'].map(lambda age : mapage(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_train['agedays']=df_c_train['age'].map(lambda age : mapage(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we encode the gender to [0,1] normalize the features :\n",
    "df_c[\"gender\"].replace({'Male': int(0), \"Female\": int(1)} , inplace=True)\n",
    "df_c_train[\"gender\"].replace({'Male': int(0), \"Female\": int(1)} , inplace=True)\n",
    "print(df_c.gender.value_counts(dropna=False) )\n",
    "print(df_c_train.gender.value_counts(dropna=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.drop(columns=['overall','age'] , inplace=True)\n",
    "df_c_train.drop(columns=['overall','age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Min Max scaler to normalize the features before feeding KNN imputer because // measurment distance classifier need normalizeed feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# we fit on the training data \n",
    "scaler.fit(df_c_train)\n",
    "# we used the fitted scaler to transform all on the training + Test  data \n",
    "df_c[df_c.columns] = scaler.transform(df_c[df_c.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "### use the KNN imputer to impute the missing values \n",
    "## we set the k = 50 to have a a more accurate results due to we may have more than 20 consecutive NANS in the neighbors \n",
    "## because KNN imputer produce floats we need to round the output for the gender to have [0/1]\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=50)\n",
    "imputed_gender = imputer.fit_transform(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_gender_df=pd.DataFrame(data = imputed_gender,columns= df_c.columns  , index = df_v2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_gender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replacing the columns after imputation \n",
    "df_v2.drop(columns=[\"gender\", \"abv\" ,'apperance', 'aroma','palate', 'taste','age'] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2 = pd.concat([df_v2, imputed_gender_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the shapes and indexes are true after the concatination \n",
    "print(df_v2.shape)\n",
    "print(imputed_gender_df.shape )\n",
    "sum(imputed_gender_df.index == df_v2.index ) / len(df_v2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.loc[:, [\"gender\", \"abv\" ,'apperance', 'aroma','palate', 'taste'] ].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-hunger",
   "metadata": {},
   "source": [
    "#### 2- \"profilename\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for this we can invent another strategy to group by quality and replace the most frequent ber review group we have 9 categories for each we can compute to most frequent profilename \n",
    "# hence we will reduce the unbalnce we will cause by imputation \n",
    "## we will consider only the training part \n",
    "mask = df.overall.notna()\n",
    "names= []\n",
    "for name , group in df_v2.loc[mask,[\"overall\" , \"profilename\"]].groupby(\"overall\"):\n",
    "    x= group[\"profilename\"].value_counts( ).index[0] \n",
    "    names.append(x)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,5.5,10 )\n",
    "for k,v in zip(x,names) :\n",
    "    df_v2[df_v2[\"overall\"] == k].profilename.fillna(value = v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the test data we will fill with the most frequent \n",
    "df[\"profilename\"].fillna(df[\"profilename\"].value_counts().index[0], inplace=True)\n",
    "np.sum(df.profilename.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.loc[~ mask,[\"profilename\"]].value_counts().index[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-sport",
   "metadata": {},
   "source": [
    "### B-feature discritization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-pharmacology",
   "metadata": {},
   "source": [
    "#### 1-\"profilename\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the feature profilename has cradinality of {df_v2.profilename.nunique()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### any value has a frequency < threshould should be mapped to others in order to reduce the features when mapping from categorical to one hot encoding // dummy encoding \n",
    "x = df.profilename.copy()\n",
    "x[x.replace(x.value_counts().to_dict()) < 50] = 'others_users'\n",
    "x.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2[\"profilename\"] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-invalid",
   "metadata": {},
   "source": [
    "#### 2- 'beer/name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the feature profilename has cradinality of {df.beerName.nunique()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"beerName\" after discritizing it it should be encoded with only 8 bits using get_dummies because this feature has no high feature importance we don't want all this high cardinality \n",
    "x = df.beerName.copy()\n",
    "x[x.replace(x.value_counts().to_dict()) < 130] = 'others'\n",
    "x.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2[\"beerName\"] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-abortion",
   "metadata": {},
   "source": [
    "#### 3- beer/Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was one the most important features extracted by Random forest regressor so we don't wnat to discretize it and it's not high cardinality \n",
    "df_v2.beerstyle.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[\"beerstyle\"] == df[\"beerName\"]\n",
    "print(f\"there is {df.loc[mask ,['beerstyle','beerName'] ].nunique()} redundant unique values between the 2 features\")\n",
    "len(df.loc[mask ,[\"beerstyle\" , \"beerName\"] ])/len(df[\"beerstyle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-guatemala",
   "metadata": {},
   "source": [
    "### C- Feature Transformation [Categorical to Numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will exclude \"text\" attribute for now hence it needs other type of transformation \n",
    "cat_col = [ 'beerstyle' , 'profilename' , \"beerName\"  ]\n",
    "df_one_h = pd.get_dummies(df_v2,columns= cat_col , drop_first=True) #we set drop_first to true to remove the orininagl encoded columns\n",
    "df_one_h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-being",
   "metadata": {},
   "source": [
    "### D- Textual Semantic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-correlation",
   "metadata": {},
   "source": [
    "#### 1- Handleing Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we found very small number of missing reviews instead of removing the rows (extreme) we decide to fill with the most frequent review's text\n",
    "p =  df_v2['text'].isnull().sum()/len(df['text'])\n",
    "print(f\"the percentage of nulls = {p}\" )\n",
    "print(f\"number of null values is {df_v2['text'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df_v2.text.value_counts().index[0]\n",
    "df_v2.text.fillna(value = x , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-evening",
   "metadata": {},
   "source": [
    "#### 2-Review Text length study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we can study the relation between the length of the review and the value of the overall review score :\n",
    "# we create a new column with the lenght of the text \n",
    "\n",
    "df_one_h[\"text_length\"] = df_one_h.text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_h[\"text_length\"].fillna(method= \"ffill\" , inplace=True)\n",
    "df_one_h[\"text_length\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lenght_overall = df_one_h[[\"text_length\" , \"overall\"]].copy(deep=True)\n",
    "plot_lenght_overall.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lenght_overall['text_length'] = plot_lenght_overall.text_length.apply(lambda x : np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lenght_overall.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot( x = 'overall',  y='text_length', data = plot_lenght_overall)\n",
    "plt.show()\n",
    "plt.savefig(\" Text)Length.png\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The analysis shows that this feature probably not useful as it is almost have similar distribuation in all review scores \n",
    "df_one_h.drop(labels=['text_length'] , axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-operations",
   "metadata": {},
   "source": [
    "#### 3- Text Cleaning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### we used iterative approch to select stop words \n",
    "from nltk.corpus import stopwords as sw\n",
    "my_stopwords = [\"tA\" , \"this\",\"that\" , \"there\" \"thi\" , \"dtype\" , \"man\" , \"one\" , \"frien\" , \"beer\",\"text\" , \"text\" , \"Ba\" , \"says\" , \"object\" , \"call\" ,   \"12oz\" ,   \"tap\" , \"two\" ,\"Name\" \\\n",
    "                  ,\"single\" , \"Thanks\" , \"Got\" ,\"Length\" , \"tap\" , \"oz\" , \"general\" , \"tan\" ,\"baby\" ,\"basically\" , \"RR\" , \"Th\" , \"nearly\" , \"see\" , \"close\" , \"November\" ,\"review\"  \\\n",
    "                  , \"called\" ,\"held\" ,\"wh\" , \"notes\" , \"Sam\" , \"BA\" ,\"sma\" ,\"san\" , \"br\" , \"name\" , \"visited\" ,\"review\" , \"bottle\" , \"with\",\"been\" , \"that\" , \"pour\" , \"poured\" , \"pours\" , \"this\" ]\n",
    "    \n",
    "stopwords =  set(sw.words('english'))\n",
    "stopwords.update(set(my_stopwords))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose WordNetLemmatizer as a tokenizer to extract tokens from text reviews \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_h[\"cleaned_Text\"] = df_one_h.text.apply(lambda text :cleaining_Text(lemmatizer ,text) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-distributor",
   "metadata": {},
   "source": [
    "#### 4-Study the most frequent words for poistive , Nutural and Negative Reviews  and update stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Study the most frequent words for poistive , Nutural and Negative Reviews \n",
    "def mapping (x):\n",
    "    if x >= 4  :\n",
    "        return 'Positive'\n",
    "    if x <= 2 :\n",
    "        return 'Negative'\n",
    "    else :\n",
    "        return 'Nutural' \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_Cloud_df = df_one_h[[\"cleaned_Text\" , \"overall\"]].copy(deep=True)\n",
    "word_Cloud_df['overall'] =  word_Cloud_df.overall.apply(mapping)\n",
    "word_Cloud_df.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive = \" \".join(review for review in word_Cloud_df[word_Cloud_df[\"overall\"]==\"Positive\"].cleaned_Text)\n",
    "Nutural = \" \".join(review for review in word_Cloud_df[word_Cloud_df[\"overall\"]==\"Nutural\"].cleaned_Text)\n",
    "Negative = \" \".join(review for review in word_Cloud_df[word_Cloud_df[\"overall\"]==\"Negative\"].cleaned_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_wordcloud(Positive, 'Positive'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud (Nutural, 'Nutural' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud (Negative, 'Negative' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-courage",
   "metadata": {},
   "source": [
    "### 5-Tf-Idf Vectorizer and feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are interesting in the rare words wich are probably the ones make the quality value higher we set use_idf=True\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords ,use_idf=True, norm=False , smooth_idf=True, lowercase=True ,ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pass the feature's documents of df_one_h[\"cleaned_Text\"] column to the vectorizer \n",
    "# after fitting the data will Transform a count matrix to a normalized tf or tf-idf representation \n",
    "\n",
    "docs = df_one_h[\"cleaned_Text\"]\n",
    "tfidf_vectorizer_vectors = vectorizer.fit_transform(docs) # Return Document-term matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the matrix (100000, 62641) that means :\n",
    "# 100000 rows (vectors in this case) each vector /row represnts a document\n",
    "# 62641 columns represents the terms (words) , in case of (1,1)n grams\n",
    "\n",
    "tfidf_vectorizer_vectors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we decide to select the 100/250 /500 /1K / 10K most popular words to represent an input features ( applying feature reduction)\n",
    "\n",
    "# # we defined a function so we can apply different values of N and evaluate the perfromance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_10k = selecting_terms(10000 , tfidf_vectorizer_vectors, vectorizer=vectorizer)\n",
    "# freq_5k = selecting_terms(5000 , tfidf_vectorizer_vectors, vectorizer=vectorizer)\n",
    "# freq_1k = selecting_terms(1000,tfidf_vectorizer_vectors, vectorizer=vectorizer)\n",
    "freq_750 = selecting_terms(750 , tfidf_vectorizer_vectors, vectorizer=vectorizer)\n",
    "# freq_500 = selecting_terms(500 , tfidf_vectorizer_vectors, vectorizer=vectorizer)\n",
    "# freq_250 = selecting_terms(250 , tfidf_vectorizer_vectors, vectorizer=vectorizer)\n",
    "# freq_100 = selecting_terms(100 , tfidf_vectorizer_vectors, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_500[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.utils13 import word_dataframe\n",
    "# freq_1k_df = word_dataframe(freq_1k, tfidf_vectorizer_vectors ,vectorizer , df_one_h)\n",
    "freq_750_df = word_dataframe(freq_750, tfidf_vectorizer_vectors ,vectorizer , df_one_h)\n",
    "# freq_500_df = word_dataframe(freq_500, tfidf_vectorizer_vectors ,vectorizer , df_one_h)\n",
    "# freq_250_df = word_dataframe(freq_250, tfidf_vectorizer_vectors ,vectorizer , df_one_h)\n",
    "# freq_100_df = word_dataframe(freq_100, tfidf_vectorizer_vectors ,vectorizer , df_one_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first we make sure the output is as excpected \n",
    "print(freq_250_df.shape)\n",
    "print(sum(df_one_h.index == freq_250_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-jordan",
   "metadata": {},
   "source": [
    "#### creating Word Cloud For Tf-Idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "cop = freq_250_df.transpose(copy=True)\n",
    "cop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = cop.sum(axis=\"columns\")\n",
    "tf_df = tf_df.sort_values( ascending = False)\n",
    "tf_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='white',stopwords=stopwords, max_words=100,max_font_size=40, scale=3,random_state=1 )\n",
    "wc.generate_from_frequencies(tf_df)\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 12))\n",
    "plt.axis('off') \n",
    "fig.suptitle(\"TF-IDF WORDCLOUD\", fontsize=20)\n",
    "fig.subplots_adjust(top=2.3)\n",
    "\n",
    "plt.imshow(wc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "## then we concatinate the 2 data frames \n",
    "# df_1K = pd.concat([df_one_h , freq_1k_df] , axis=1 )\n",
    "df_750 = pd.concat([df_one_h , freq_750_df] , axis=1 )\n",
    "# df_500 = pd.concat([df_one_h , freq_500_df] , axis=1 )\n",
    "# df_250 = pd.concat([df_one_h , freq_250_df] , axis=1 )\n",
    "# df_100 = pd.concat([df_one_h , freq_100_df] , axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-collapse",
   "metadata": {},
   "source": [
    "#### 3- Training with Textual Feartures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropped_Columns = [ 'text', 'user/birthdayRaw','user/birthdayUnix' , \"cleaned_Text\"  ] \n",
    "X_train, X_valid, y_train, y_valid ,X_train_valid ,y_train_valid,X_test,y_test,feature_names, index = train_val_test( Dropped_Columns ,df_750)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-champion",
   "metadata": {},
   "source": [
    "##### A-training models baselines  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Lasso Default :\n",
    "lasso_default = Lasso( tol = 0.001 , alpha = 0.001)\n",
    "make_regression(lasso_default ,X_train , y_train  ,X_valid, y_valid )\n",
    "\n",
    "# Ridge Regularization model:\n",
    "ridge_default =  Ridge()\n",
    "make_regression(ridge_default ,X_train , y_train ,X_valid, y_valid  )\n",
    "\n",
    "# RANDOM FOREST REGRESSOR \n",
    "RF_default = RandomForestRegressor(random_state=42 , n_jobs=-1)\n",
    "make_regression(RF_default ,X_train , y_train , X_valid, y_valid )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-compound",
   "metadata": {},
   "source": [
    "#### Predection of Basline Models on Test Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(RF_default ,X_train_valid, y_train_valid,X_test, \"RandomForest_BEST_with_Text\",index)\n",
    "print_results(lasso_default ,X_train_valid, y_train_valid,X_test ,\"LASSO_BEST_with_Text\", index)\n",
    "print_results(ridge_default,X_train_valid, y_train_valid,X_test , \"Ridge_BEST_with_Text\" , index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-pitch",
   "metadata": {},
   "source": [
    "### Randomize Grid Search Results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_d = Lasso()\n",
    "Lasso_best = RandomizeGridSearch(lasso_d ,lasso_grid ,X_train_valid , y_train_valid, n_iter=100 ,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "Ridge_best = RandomizeGridSearch ( ridge , Ridge_random_grid ,X_train_valid , y_train_valid,100 ,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor(random_state=42 )\n",
    "RF_best = RandomizeGridSearch (RF , RF_grid ,X_train_valid , y_train_valid,100 ,3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-studio",
   "metadata": {},
   "source": [
    "##### compute the feature importance by the regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature_names = df_drop[train_valid_mask].drop(columns=[\"overall\"]).columns # extract the features from the dev set \n",
    "sorted(zip(feature_names, RF_default. feature_importances_), key=lambda x: x[1],reverse=True)[:100] # sorting the feature descending "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-imperial",
   "metadata": {},
   "source": [
    "#### B-Predections of best Models on Test Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(RF_best ,X_train_valid, y_train_valid,X_test, \"RandomForest_BEST_with_Textg\",index)\n",
    "print_results(Ridge_best ,X_train_valid, y_train_valid,X_test ,\"LASSO_BEST_with_Textg\", index)\n",
    "print_results(Lasso_best,X_train_valid, y_train_valid,X_test , \"Ridge_BEST_with_Textg\" , index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
